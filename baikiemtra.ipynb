{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('boston.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NGONNGU</th>\n",
       "      <th>LOGIC</th>\n",
       "      <th>UNGXU</th>\n",
       "      <th>DINHHUONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.25</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.25</td>\n",
       "      <td>1.50</td>\n",
       "      <td>6.25</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.25</td>\n",
       "      <td>3.75</td>\n",
       "      <td>4.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>5.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.25</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4.25</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    NGONNGU  LOGIC  UNGXU DINHHUONG\n",
       "0      3.25   3.25   4.50        No\n",
       "1      6.00   4.00   3.50       Yes\n",
       "2      5.00   6.75   4.00        No\n",
       "3      4.25   4.25   5.25        No\n",
       "4      4.25   4.50   5.00        No\n",
       "..      ...    ...    ...       ...\n",
       "95     5.25   1.50   6.25       Yes\n",
       "96     5.25   3.75   4.75        No\n",
       "97     7.00   8.00   4.00       Yes\n",
       "98     5.00   3.50   5.50        No\n",
       "99     5.25   2.50   4.25       Yes\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.rename(columns={'TOANLOGICPHANTICH' : 'LOGIC',\n",
    "                    'GIAIQUYETVANDE': 'UNGXU',\n",
    "                    'DINHHUONGNGHENGHIEP' : 'DINHHUONG'}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NGONNGU</th>\n",
       "      <th>LOGIC</th>\n",
       "      <th>UNGXU</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.00</td>\n",
       "      <td>6.75</td>\n",
       "      <td>4.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.25</td>\n",
       "      <td>4.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.25</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NGONNGU  LOGIC  UNGXU    Yes\n",
       "0     3.25   3.25   4.50  False\n",
       "1     6.00   4.00   3.50   True\n",
       "2     5.00   6.75   4.00  False\n",
       "3     4.25   4.25   5.25  False\n",
       "4     4.25   4.50   5.00  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Do biến DINH HUỐNG là dạng categorical values (định tính) nên cần 4 trong bài này biến ĐỊNH HƯƠNG chỉ có 2 gia tri MolYes nen ta đã đã\n",
    "\n",
    "# A nhưng nếu như số lượng giá trị nhiều hơn 2 thì ta còn dùng PHOE 1 biến đổi về dạng một vector số tương ứng\n",
    "dinhhuong = pd.get_dummies(df[ 'DINHHUONG'], drop_first=True)\n",
    "df.drop('DINHHUONG', axis=1, inplace=True)\n",
    "df = pd.concat([df, dinhhuong], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['LSTAT'].values #input\n",
    "y = df['MEDV'].values #output\n",
    "#Chia tách ra training và testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25.3, 23.3,  7.2, 21.2, 11.7, 27. , 29.6, 26.5, 43.5, 23.6, 11. ,\n",
       "       33.4, 36. , 36.4, 19. , 20.2, 34.9, 50. , 19.3, 14.9, 26.6, 19.9,\n",
       "       24.8, 21.2, 23.9, 20.6, 23.1, 28. , 20. , 23.1, 25. ,  9.7, 23.9,\n",
       "       36.1, 13.4, 12.7, 39.8, 10.4, 20.6, 17.8, 19.5, 23.7, 28.5, 24.3,\n",
       "       23.8, 19.1, 28.4, 20.5, 33.8, 14.5, 20.4, 16. , 13.3, 30.8, 27.5,\n",
       "       24.4, 24.4, 25.1, 43.8, 21.9, 26.2, 14.2, 20.8, 20.1, 23.1, 13.1,\n",
       "       16.2, 24.8, 20.2, 22.5, 14.8, 28.7, 20.1, 23.4, 32. , 19.1, 50. ,\n",
       "       20.9, 21.7, 22. , 17.2, 30.3, 12.3, 21.4, 20.5, 35.2, 19.6, 22. ,\n",
       "       21.7, 14.1, 21.1, 15. , 11.9, 20. , 41.3, 18.7, 50. , 50. , 18.4,\n",
       "       17.9, 28.1, 16.1, 17.2, 28.6, 23.6, 20.4, 19.6, 18.8, 22.6, 17.7,\n",
       "       30.5, 18.2, 20.6, 24.4, 17.3, 13.3, 22.8, 20.5, 21.2, 18.8, 18.9,\n",
       "       18.2, 23.1, 32.7, 24. , 10.2, 19.5, 33.1, 13.4, 15.2, 24.8, 24.3,\n",
       "        9.5, 24.2, 18.5, 44. , 50. , 24.7, 21.5,  8.4, 21.8, 50. , 23.8,\n",
       "       32.4, 24.4, 17.6, 29.8,  9.6, 16.7, 13.8, 32. , 16.1,  8.3, 26.6,\n",
       "       14.3, 15. , 28.4, 32.2, 17.1, 29.4, 10.4, 16.8, 31.5, 27.5, 46.7,\n",
       "       27.5, 17.2, 23.4, 31.6, 13.8, 22. , 17. , 24.8, 24.3, 25.2, 21.2,\n",
       "       20.6, 18.7,  5.6, 19.3, 19.8, 22.3, 20.3, 12. , 23.9, 16.5, 13.2,\n",
       "       33.2, 10.5,  7.5, 27.5, 18.4, 23.2, 13.8, 35.4, 23. , 25. ,  7.2,\n",
       "       14.4,  8.8, 22.7, 13.1, 18.9, 25. ,  8.5, 16.1, 29. , 23.1, 19.3,\n",
       "       33.1, 24.6, 23. , 15.2, 27.1, 19.6, 24.5, 20.3, 34.9, 17.1, 15.6,\n",
       "       26.4, 22.6, 15.6, 29. , 21.2, 22.4, 13.5, 11.7, 17.1, 31.7, 28.7,\n",
       "       24.7, 19. ,  7.2, 13.8, 12.8, 36.2, 38.7, 18.5, 29.1, 20.4, 11.3,\n",
       "       17.4,  8.7, 18.9, 23.2, 22.2, 29.1, 34.6, 25. , 23.2, 37.9,  7. ,\n",
       "       18.2, 19.3, 26.7, 19.2, 30.1, 20.6, 50. , 18.7, 20.6, 31.1, 14. ,\n",
       "       17.8, 42.3, 15.3, 18.5, 21.4, 15. , 20.7, 21.4, 21.7, 22. , 31.6,\n",
       "       22. , 10.2, 22.6, 20. , 17.8, 13.6, 11.8, 19.4, 21.4, 32.9, 20.8,\n",
       "       31. , 17.5, 15.4, 10.8, 34.7, 25. , 48.8, 42.8, 19.5, 30.1, 22.2,\n",
       "       50. , 23.1, 32.5, 19.6, 14.9, 26.4, 37. , 24.1, 24.5, 23.7,  7. ,\n",
       "       22.2, 23.3, 15.6, 13.4, 30.7, 22.3, 17.4, 50. , 22.9, 19.7, 15.6,\n",
       "       17.8, 10.9, 35.1, 15.7, 50. , 22.8, 19.9, 20.1, 19.4, 46. , 23.2,\n",
       "       37.6, 23.1, 13.9, 33.3, 33. , 19.9, 20.3, 50. , 19.4, 19.5, 22.8,\n",
       "       16.6, 20. , 24.7, 45.4, 33.4, 21.4, 19.4,  5. ,  7.4, 20.1, 12.7,\n",
       "       20.3, 14.1, 18.3, 19.9, 23.3, 36.5, 20. , 17.8,  8.8, 21.6, 21.6,\n",
       "       15.2, 19.8, 21. , 27.1, 16.8, 14.4, 22.5, 18.6, 20.1, 19.6, 25. ,\n",
       "       17.4, 19.7,  5. , 16.3, 13.1, 29.6, 13.1, 19.1, 12.1, 21.7, 21.9,\n",
       "       33.2, 29.9, 35.4, 15.1, 31.5, 21.7, 16.4, 14.3, 11.8, 14.1, 21.1,\n",
       "       18.4, 48.5, 13.8, 20.9, 22.8, 12.5, 24. , 21. ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 5.81  6.86 30.81 12.34 17.16  5.5  13.15  7.67  3.16  9.04 21.52  6.47\n  7.79  2.87  9.74 11.69  1.98  7.44  9.97 18.71  4.84 14.19  9.51 12.92\n  8.58  9.08 14.69  5.29 14.15 10.36  6.21 25.68  7.22  6.93 26.82 19.01\n  7.56 17.21  5.57 18.46 18.66  6.36  3.33  9.16  7.2  21.32  6.65 17.93\n  9.59 19.88  8.26 14.44 21.24  4.32  7.12  7.73 14.66  9.54  3.57  5.29\n  6.56 15.7  14.1  12.93  6.36 23.69 17.19  6.72 10.29 18.06 17.28  5.7\n 14.76  7.54  6.68 12.03  1.73  8.79 21.46  8.2  21.22  8.61 24.56 14.81\n 10.15  6.58  9.22 14.37 15.71 18.13 13.   13.44  7.88 14.7   4.59  9.29\n  4.45  8.88 16.59 34.37  9.38 17.27 12.67  6.27  5.5   7.7  12.26 17.58\n  9.64 14.65  4.69 10.26 13.34  5.9  25.41 21.32 10.16  9.43 10.58 16.21\n 17.1  11.28  6.58  5.49  4.98 21.78 16.47  4.16 17.44 18.06  6.07 11.65\n 24.08  6.72 11.74  3.11  3.16 10.13 14.1  34.02 12.01  3.32 12.14  3.53\n 10.97 12.5   4.56 18.05 18.68 27.8   2.98 12.03 19.77  5.89 16.22 10.11\n  8.93  7.85 12.43  5.33 26.64 14.64  3.76 19.78  3.92  9.42 26.4   8.43\n  6.36 18.14  6.48 15.12  3.59  6.43  6.59  9.55 11.45 17.09 26.77 23.98\n 12.27 11.32  9.1  24.91  9.62 29.93 27.71  6.19 22.11 25.79  9.93 12.8\n  7.14 37.97  4.81 10.74  7.01 29.05 30.81 20.62 11.48 18.35  9.68  9.5\n 27.38 12.64  8.05 17.6  10.21  4.86  6.29 10.5  17.73  7.39 13.83  9.52\n  9.97  4.56 14.59 16.3  13.98 10.87 17.31  4.74 12.04 16.03 16.94 15.17\n 19.52  5.25  9.69  5.77 17.15 20.32 34.77 22.88  9.45  4.21 10.45  7.19\n 15.37 23.6  14.43 26.45 14.8  10.11 12.79  4.38  6.62  7.79 14.36  4.82\n 36.98  8.05 13.44  9.71 12.6   4.5   8.51  3.26 13.15 10.59  5.03 24.16\n 28.32  3.11 12.12 10.56 13.11 20.45 13.65 11.34 17.27 11.38  3.95  9.5\n 30.62 12.67 11.41 16.74 21.02 23.98  7.83  8.94  4.45 10.27 11.25 15.1\n 21.45 23.79  4.03  5.28  5.91  3.54 13.99  6.9   5.68  3.73  6.87  5.68\n 13.28 16.23  8.67  5.1   6.78  5.99  5.19 23.97  8.44  7.37 26.42 23.29\n 14.79  7.6  16.9   3.7   7.51 21.14 15.02 17.6  21.08  4.85 27.26  2.97\n 10.45 14.13 12.33 15.79  3.01 18.76  3.13 13.33 16.51  4.08  8.05  8.47\n 15.84  9.53 15.55  9.8   4.54 14.81 11.97  7.44  3.76  2.94 13.22 16.2\n 22.98 31.99 13.35 22.6  14.27 19.69 15.76 16.29 13.51  8.1  23.09 18.33\n 30.63  9.14  7.9  18.72 15.94 12.73 19.15 14.33 34.41 12.86  7.79 12.4\n 12.87  9.47 13.09 13.45 30.59 20.08 16.14  3.53 17.12 18.13 20.31 13.27\n  6.57  6.05  6.92  4.59 17.11  4.73  9.88 16.42 18.34 29.29 18.13  8.01\n 15.03  3.81 15.17  9.25  5.52 19.37 10.88  8.77].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\python\\baikiemtra.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/baikiemtra.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/baikiemtra.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifier\u001b[39m=\u001b[39mLogisticRegression()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/python/baikiemtra.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\teoqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\teoqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1205\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1207\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1208\u001b[0m     X,\n\u001b[0;32m   1209\u001b[0m     y,\n\u001b[0;32m   1210\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1211\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1212\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1213\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1214\u001b[0m )\n\u001b[0;32m   1215\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\teoqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\teoqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\teoqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    939\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 940\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    941\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    945\u001b[0m         )\n\u001b[0;32m    947\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array\u001b[39m.\u001b[39mdtype, \u001b[39m\"\u001b[39m\u001b[39mkind\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    948\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    949\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    950\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 5.81  6.86 30.81 12.34 17.16  5.5  13.15  7.67  3.16  9.04 21.52  6.47\n  7.79  2.87  9.74 11.69  1.98  7.44  9.97 18.71  4.84 14.19  9.51 12.92\n  8.58  9.08 14.69  5.29 14.15 10.36  6.21 25.68  7.22  6.93 26.82 19.01\n  7.56 17.21  5.57 18.46 18.66  6.36  3.33  9.16  7.2  21.32  6.65 17.93\n  9.59 19.88  8.26 14.44 21.24  4.32  7.12  7.73 14.66  9.54  3.57  5.29\n  6.56 15.7  14.1  12.93  6.36 23.69 17.19  6.72 10.29 18.06 17.28  5.7\n 14.76  7.54  6.68 12.03  1.73  8.79 21.46  8.2  21.22  8.61 24.56 14.81\n 10.15  6.58  9.22 14.37 15.71 18.13 13.   13.44  7.88 14.7   4.59  9.29\n  4.45  8.88 16.59 34.37  9.38 17.27 12.67  6.27  5.5   7.7  12.26 17.58\n  9.64 14.65  4.69 10.26 13.34  5.9  25.41 21.32 10.16  9.43 10.58 16.21\n 17.1  11.28  6.58  5.49  4.98 21.78 16.47  4.16 17.44 18.06  6.07 11.65\n 24.08  6.72 11.74  3.11  3.16 10.13 14.1  34.02 12.01  3.32 12.14  3.53\n 10.97 12.5   4.56 18.05 18.68 27.8   2.98 12.03 19.77  5.89 16.22 10.11\n  8.93  7.85 12.43  5.33 26.64 14.64  3.76 19.78  3.92  9.42 26.4   8.43\n  6.36 18.14  6.48 15.12  3.59  6.43  6.59  9.55 11.45 17.09 26.77 23.98\n 12.27 11.32  9.1  24.91  9.62 29.93 27.71  6.19 22.11 25.79  9.93 12.8\n  7.14 37.97  4.81 10.74  7.01 29.05 30.81 20.62 11.48 18.35  9.68  9.5\n 27.38 12.64  8.05 17.6  10.21  4.86  6.29 10.5  17.73  7.39 13.83  9.52\n  9.97  4.56 14.59 16.3  13.98 10.87 17.31  4.74 12.04 16.03 16.94 15.17\n 19.52  5.25  9.69  5.77 17.15 20.32 34.77 22.88  9.45  4.21 10.45  7.19\n 15.37 23.6  14.43 26.45 14.8  10.11 12.79  4.38  6.62  7.79 14.36  4.82\n 36.98  8.05 13.44  9.71 12.6   4.5   8.51  3.26 13.15 10.59  5.03 24.16\n 28.32  3.11 12.12 10.56 13.11 20.45 13.65 11.34 17.27 11.38  3.95  9.5\n 30.62 12.67 11.41 16.74 21.02 23.98  7.83  8.94  4.45 10.27 11.25 15.1\n 21.45 23.79  4.03  5.28  5.91  3.54 13.99  6.9   5.68  3.73  6.87  5.68\n 13.28 16.23  8.67  5.1   6.78  5.99  5.19 23.97  8.44  7.37 26.42 23.29\n 14.79  7.6  16.9   3.7   7.51 21.14 15.02 17.6  21.08  4.85 27.26  2.97\n 10.45 14.13 12.33 15.79  3.01 18.76  3.13 13.33 16.51  4.08  8.05  8.47\n 15.84  9.53 15.55  9.8   4.54 14.81 11.97  7.44  3.76  2.94 13.22 16.2\n 22.98 31.99 13.35 22.6  14.27 19.69 15.76 16.29 13.51  8.1  23.09 18.33\n 30.63  9.14  7.9  18.72 15.94 12.73 19.15 14.33 34.41 12.86  7.79 12.4\n 12.87  9.47 13.09 13.45 30.59 20.08 16.14  3.53 17.12 18.13 20.31 13.27\n  6.57  6.05  6.92  4.59 17.11  4.73  9.88 16.42 18.34 29.29 18.13  8.01\n 15.03  3.81 15.17  9.25  5.52 19.37 10.88  8.77].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier=LogisticRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32md:\\python\\Lesson 9.ipynb Cell 9\u001b[0m line \u001b[0;36m6\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lesson%209.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump(classifier,\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlogisticregression.sav\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lesson%209.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m loaded_model\u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mlogisticregression.sav\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/python/Lesson%209.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m vNN\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mnhap nn :\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lesson%209.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m vlogic\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnhap lg :\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/python/Lesson%209.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m vUX\u001b[39m=\u001b[39m\u001b[39mfloat\u001b[39m(\u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnhap ux :\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '\\\\'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier,open('logisticregression.sav','wb'))\n",
    "\n",
    "loaded_model= pickle.load(open('logisticregression.sav','rb'))\n",
    "\n",
    "vNN=float(input(\"nhap nn :\"))\n",
    "vlogic=float(input(\"nhap lg :\"))\n",
    "vUX=float(input(\"nhap ux :\"))\n",
    "\n",
    "y_pred=loaded_model.predict([[vNN,vlogic,vUX]])\n",
    "print('Dự báo định hướng:'+str(y_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z =-1.2971+0.3197+NN-0.043*LG+0.0289*UX\n",
    "f(z) = 1/(1+e^-Z)\n",
    "sigmod\n",
    "f(z) = threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.75, 4.5 , 4.25],\n",
       "       [4.75, 2.  , 5.5 ],\n",
       "       [3.5 , 4.75, 3.5 ],\n",
       "       [5.75, 3.5 , 4.25],\n",
       "       [4.75, 6.5 , 8.  ],\n",
       "       [2.75, 3.75, 5.  ],\n",
       "       [2.25, 3.5 , 5.  ],\n",
       "       [3.75, 4.  , 3.5 ],\n",
       "       [2.  , 5.25, 3.5 ],\n",
       "       [4.  , 4.75, 5.5 ],\n",
       "       [5.  , 4.  , 6.75],\n",
       "       [2.5 , 3.5 , 6.5 ],\n",
       "       [5.25, 4.5 , 4.75],\n",
       "       [4.25, 2.75, 3.25],\n",
       "       [5.  , 3.5 , 5.5 ],\n",
       "       [1.5 , 4.5 , 5.5 ],\n",
       "       [4.75, 4.75, 4.5 ],\n",
       "       [6.5 , 4.5 , 8.  ],\n",
       "       [2.25, 4.  , 4.25],\n",
       "       [2.5 , 2.75, 5.5 ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True, False, False, False, False,\n",
       "       False,  True, False,  True,  True,  True, False,  True,  True,\n",
       "       False, False])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Default threshold is 0.5\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54215376 0.45784624]\n",
      " [0.42686728 0.57313272]\n",
      " [0.56989436 0.43010564]\n",
      " [0.37434035 0.62565965]\n",
      " [0.45685782 0.54314218]\n",
      " [0.60701717 0.39298283]\n",
      " [0.64196612 0.35803388]\n",
      " [0.54218784 0.45781216]\n",
      " [0.68624869 0.31375131]\n",
      " [0.51592045 0.48407955]\n",
      " [0.41956957 0.58043043]\n",
      " [0.61315482 0.38684518]\n",
      " [0.41943042 0.58056958]\n",
      " [0.49065667 0.50934333]\n",
      " [0.42312774 0.57687226]\n",
      " [0.70106665 0.29893335]\n",
      " [0.46326149 0.53673851]\n",
      " [0.30601715 0.69398285]\n",
      " [0.65184076 0.34815924]\n",
      " [0.6123461  0.3876539 ]]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict_proba(X_test))\n",
    "#0.5421 Giá trị mô hình hồi quy tuyến tính là z\n",
    "#0.4578 Giá trị mô hình sau khi đi qua hàm 1(1+e^(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction with 0.9: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Prediction with 0.9: ')\n",
    "y_pred_test_new_threshold = (classifier.predict_proba(X_test)[:,1] >= 0.9).astype(int)\n",
    "y_pred_test_new_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted\n",
       "0     True      False\n",
       "1    False       True\n",
       "2     True      False\n",
       "3     True       True\n",
       "4    False       True\n",
       "5    False      False\n",
       "6    False      False\n",
       "7     True      False\n",
       "8    False      False\n",
       "9     True      False\n",
       "10   False       True\n",
       "11    True      False\n",
       "12   False       True\n",
       "13   False       True\n",
       "14   False       True\n",
       "15   False      False\n",
       "16   False       True\n",
       "17    True       True\n",
       "18    True      False\n",
       "19   False      False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Default threshold = 0.5\n",
    "result = pd.DataFrame ({'Actual': y_test.flatten(), 'Predicted': y_pred_test})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả dự báo chính xác là: 35%\n",
    "(0 0) (1 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 7],\n",
       "       [6, 2]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "cf_matrix\n",
    "#Giá trị\n",
    "#TP (Actual = 1, Prediction = 1) = 2\n",
    "#FP (Actual = 0, Prediction = 1) = 7\n",
    "#FN (Actual = 1, Prediction = 0) = 6\n",
    "#TN (Actual = 0, Prediction = 0) = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP + TN /(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 23.52222222222222, 'Prediction label')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(pd.DataFrame(cf_matrix), annot = True, cmap=\"YlGnBu\", fmt = 'g')\n",
    "plt.title('Confusion matrix', y = 1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Prediction label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Các độ đo đánh giá mô hình phân lớp\n",
    "- N là số lượng mẫu = TP+FP+FN+TN\n",
    "- TP,FP,FN,TN\n",
    "- accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "- Precision = TP/(TP+FP)\n",
    "- Recall = TP/(TP+FN)\n",
    "- F1-Score = 2*Precision *Recall/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not oriented       0.45      0.42      0.43        12\n",
      "    Oriented       0.22      0.25      0.24         8\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.34      0.33      0.34        20\n",
      "weighted avg       0.36      0.35      0.35        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ('Not oriented', 'Oriented')\n",
    "print(classification_report(y_test, y_pred_test, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự báo định hướng:False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(classifier,open('logisticregression.sav','wb'))\n",
    "\n",
    "loaded_model= pickle.load(open('logisticregression.sav','rb'))\n",
    "\n",
    "vNN=float(input(\"nhap nn :\"))\n",
    "vlogic=float(input(\"nhap lg :\"))\n",
    "vUX=float(input(\"nhap ux :\"))\n",
    "\n",
    "y_pred=loaded_model.predict([[vNN,vlogic,vUX]])\n",
    "print('Dự báo định hướng:'+str(y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
